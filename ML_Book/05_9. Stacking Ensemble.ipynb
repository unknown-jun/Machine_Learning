{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26a7f34",
   "metadata": {},
   "source": [
    "# 스태킹 앙상블 개요\n",
    "![image](https://user-images.githubusercontent.com/70187490/129557876-c045a61f-0f5f-4bd9-8a0c-12b9abe61ff6.png)\n",
    "\n",
    "- 스태킹(Stacking)은 개별적인 여러 알고리즘을 서로 결합해 예측 결과를 도출한다는 점에서 앞에 소개한 배깅(Bagging) 및 부스팅(Boosting)과 공통점을 가지고 있음  \n",
    "- 하지만 가장 큰 차이점은 개별 알고리즘으로 예측한 데이터를 기반으로 다시 예측을 수행\n",
    "- 즉, 개별 알고리즘의 예측 결과 데이터 세트를 최종적인 메타 데이터 세트로 만들어 별도의 ML 알고리즘으로 최종 학습을 수행하고 테스트 기반으로 다시 최종 예측을 수행하는 방식\n",
    "\n",
    "스태킹 모델은 두 종류의 모델이 필요함\n",
    "1. 개별적인 기반 모델\n",
    "2. 이 개별 기반 모델의 예측 데이터를 학습 데이터로 만들어서 학습하는 최종 메타 모델\n",
    "-> 여러 개별 모델의 예측 데이터를 각각 스태킹 형태로 결합해 최종 메타 모델의 학습용 피처 데이터 세트와 테스트용 피처 데이터 세트를 만드는 것  \n",
    "\n",
    "스태킹을 현실 모델에 적용하는 경우는 그렇게 많지 않지만, 캐글과 같은 대회에서 점수를 올리기 위해서 사용됌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05d775",
   "metadata": {},
   "source": [
    "<스태킹 앙상블 적용 과정>\n",
    "\n",
    "<br>\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/70187490/129564391-dec277a7-9e54-47e6-84b6-ac221b7e5699.png)\n",
    "\n",
    "\n",
    "\n",
    "M개의 로우, N개의 피처(칼럼)을 가진 데이터 세트에 ML 알고리즘 모델 3개로 적용한 스태킹이라면\n",
    "- 1. 먼저 모델별로 각각 학습 시킨 뒤 예측을 수행하면 각각 M개의 로우를 가진 1개의 레이블 값을 도출\n",
    "- 2. 모델별로 도출된 예측 레이블 값을 다시 합해서(스태킹) 새로운 데이터 세트를 만들고 \n",
    "- 3. 이렇게 스태킹된 데이터 세트에 대해 최종 모델을 적용해 최종 예측을 하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d23d48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "print(skl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0df5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer( )\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994e0f5",
   "metadata": {},
   "source": [
    "스태킹에 사용될 알고리즘 클래스를 생성  \n",
    "개별 모델은 KNN, 랜덤포레스트, 결정트리, 에이다부스트  \n",
    "이들 모델의 예측 결과를 합한 데이터 세트로 학습/예측하는 최종 모델은 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4983497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델 생성\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=200)\n",
    "\n",
    "# 스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델\n",
    "lr_final = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d5faff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.9123\n",
      "랜덤 포레스트 정확도: 0.9649\n",
      "결정트리 정확도: 0.9123\n",
      "에이다부스트 정확도: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델들을 학습\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 세트를 생성하고 개별 모델의 정확도 측정\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('결정트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e20a3a",
   "metadata": {},
   "source": [
    "개별 알고리즘으로부터 예측된 예측값을 칼럼 레벨로 옆으로 붙여서 피처값으로 만들어, 최종 메타 모델인 로지스틱 회귀에서 학습 데이터로 다시 사용  \n",
    "반환된 예측 데이터 세트는 1차원 형태의 ndarray이므로 먼저 반환된 예측 결과를 행 형태로 붙인 뒤, 넘파이의 transpose()를 이용해 행과 열 위치를 바꾼 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc53b686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "pred=np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치 교환. 칼럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0400d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9825\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(pred, y_test)\n",
    "final = lr_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a48da",
   "metadata": {},
   "source": [
    "# CV 세트 기반의 스태킹\n",
    "CV 세트 기반의 스태킹 모델은 과적합을 개선하기 위해 최종 메타 모델을 위한 데이터 세트를 만들 때 교차 검증 기반으로 예측된 결과 데이터 세트를 이용함  \n",
    "개별 모델들이 각각 교차 검증으로 메타 모델을 위한 학습용 스태킹 데이터 생성과 예측을 위한 테스트용 스태킹 데이터를 생성한 뒤 이를 기반으로 메타 모델이 학습과 예측을 수행  \n",
    "이는 다음과 같은 2단계 스텝으로 구분 가능\n",
    "\n",
    "- 스텝1: 각 모델별로 원본 학습/테스트를 예측한 결과값을 기반으로 메타 모델을 위한 학습용/테스트용 데이터를 생성\n",
    "- 스텝2: 스탭 1에서 개별 모델들이 생성한 학습용 데이터를 모두 스태킹 형태로 합쳐서 메타모델이 학습할 최종 학습용 데이터 세트를 생성  \n",
    "마찬가지로 각 모델들이 생성한 테스트용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 예측할 최종 테스트 데이터 세트를 생성함  \n",
    "메타 모델은 최종적으로 생성된 학습 데이터 세트와 원본 학습 데이터의 레이블 데이터를 기반으로 학습한 뒤,  \n",
    "최종적으로 생성된 테스트 데이터 세트를 예측하고, 원본 테스트 데이터의 레이블 데이터를 기반으로 평가함  \n",
    "\n",
    "핵심은 개별 모델에서 메타 모델인 2차 모델에서 사용될 학습용 데이터와 테스트용 데이터를 교차 검증을 통해서 생성  \n",
    "스텝 1은 개별 모델 레벨에서 수행하는 것이며, 이러한 로직은 여러 개의 개별 모델에서 동일하게 수행  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb93f9",
   "metadata": {},
   "source": [
    "먼저 학습용 데이터를 N개의 폴드(Fold)로 나눔(3개로 가정)  \n",
    "3개의 폴드세트이므로 3번의 유사한 반복 작업을 수행하고, 마지막 3번째 반복에서 개별 모델의 예측 값으로 학습 데이터와 테스트 데이터를 생성  \n",
    "\n",
    "주요 프로세스는 다음과 같음\n",
    "1. 학습용 데이터를 3개의 폴드로 나누되, 2개의 폴드는 학습을 위한 데이터 폴드로, 나머지 1개의 폴드는 검증을 위한 데이터 폴드로 나눔  \n",
    "이렇게 두개의 폴드로 나뉜 학습 데이터를 기반으로 개별 모델을 학습시킴\n",
    "2. 이렇게 학습된 개별 모델은 검증 폴드 1개 데이터로 예측하고 그 결과를 저장  \n",
    "이러한 로직을 3번 반복하면서 학습 데이터와 검증 데이터 세트를 변경해가면서 학습 후 예측 결과를 별도로 저장함  \n",
    "이렇게 만들어진 예측 데이터는 메타 모델을 학습시키는 학습 데이터로 사용됌  \n",
    "3. 2개의 학습 폴드 데이터로 학습된 개별 모델은 원본 테스트 데이터로 예측하여 예측값을 생성  \n",
    "마찬가지로 이러한 로직을 3번 반복하면서 이 예측값의 평균으로 최종 결괏값을 생성하고  \n",
    "이를 메타 모델을 위한 테스트 데이터로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1e64d",
   "metadata": {},
   "source": [
    "1. 3개의 폴드만큼 반복을 수행하면서 스태킹 데이터를 생성하는 첫 번째 반복\n",
    "![image](https://user-images.githubusercontent.com/70187490/129577007-b1a9a650-0f3a-4007-8842-863b6342eeb0.png)\n",
    "\n",
    "2. 스태킹 데이터를 생성하는 두번째 반복\n",
    "![image](https://user-images.githubusercontent.com/70187490/129578002-c4d0d967-6554-4cbd-b88b-b9673ec54fb5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba0a5b",
   "metadata": {},
   "source": [
    "3. 스테킹 데이터를 생성하는 세번째 반복\n",
    "![image](https://user-images.githubusercontent.com/70187490/129593069-81b144be-eab4-4caa-b48a-27fa6af466a1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2db0e",
   "metadata": {},
   "source": [
    "스텝 2는 각 모델들이 스텝 1로 생성한 학습과 테스트 데이터를 모두 합쳐서 최종적으로 메타 모델이 사용할 학습 데이터와 테스트 데이터를 생성  \n",
    "메타 모델이 사용할 최종 학습 데이터와 원본 데이터의 레이블 데이터를 합쳐서 메타 모델을 학습한 후에 최종 테스트 데이터로 예측을 수행한 뒤,  \n",
    "최종 예측 결과를 원본 테스트 데이터의 레이블 데이터와 비교해 평가함\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/70187490/129867946-2535997a-c476-4667-99d4-f70e0f9c3a2b.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02e92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b1d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__, 'model 시작', end='\\t')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('#',folder_counter,end='')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        # 폴드 세트 내부에서 학습\n",
    "        model.fit(X_tr, y_tr)\n",
    "        # 폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        # 입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장.\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    # train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, \n",
    "    # test_pred_mean은 테스트 데이터\n",
    "    print()\n",
    "    return train_fold_pred, test_pred_mean  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61b29ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier model 시작\t# 0# 1# 2# 3# 4# 5# 6\n",
      "RandomForestClassifier model 시작\t# 0# 1# 2# 3# 4# 5# 6\n",
      "DecisionTreeClassifier model 시작\t# 0# 1# 2# 3# 4# 5# 6\n",
      "AdaBoostClassifier model 시작\t# 0# 1# 2# 3# 4# 5# 6\n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "986b6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 Shape: (455, 30) 원본 테스트 피처 Shape: (114, 30)\n",
      "스태킹 학습 피처 데이터 Shape: (455, 3) 스태킹 테스트 피처 데이터 Shape: (114, 3)\n"
     ]
    }
   ],
   "source": [
    "# 스탭2 구현\n",
    "# get_stacking_base_datasets()호출로 반환된 각 모델별 학습데이터와 테스트 데이터를 합치기만 됨\n",
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test), axis=1)\n",
    "print('원본 학습 피처 데이터 Shape:', X_train.shape, '원본 테스트 피처 Shape:', X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
    "      '스태킹 테스트 피처 데이터 Shape:', Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9ea2c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9561\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
